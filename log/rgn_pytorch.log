Loaded aifb dataset with 8285 entities, 91 relations and 4 classes
Using the GPU
Epoch: 0, Training Loss on 140 training data: 1.3857554197311401
Epoch: 1, Training Loss on 140 training data: 1.280261516571045
Epoch: 2, Training Loss on 140 training data: 1.128110647201538
Epoch: 3, Training Loss on 140 training data: 0.9473929405212402
Epoch: 4, Training Loss on 140 training data: 0.7625947594642639
Epoch: 5, Training Loss on 140 training data: 0.5958486199378967
Epoch: 6, Training Loss on 140 training data: 0.45802944898605347
Epoch: 7, Training Loss on 140 training data: 0.35015663504600525
Epoch: 8, Training Loss on 140 training data: 0.26823726296424866
Epoch: 9, Training Loss on 140 training data: 0.20734499394893646
Epoch: 10, Training Loss on 140 training data: 0.16272969543933868
Epoch: 11, Training Loss on 140 training data: 0.1302865445613861
Epoch: 12, Training Loss on 140 training data: 0.10643789917230606
Epoch: 13, Training Loss on 140 training data: 0.0883123129606247
Epoch: 14, Training Loss on 140 training data: 0.07386398315429688
Epoch: 15, Training Loss on 140 training data: 0.06185406446456909
Epoch: 16, Training Loss on 140 training data: 0.05160820856690407
Epoch: 17, Training Loss on 140 training data: 0.042764753103256226
Epoch: 18, Training Loss on 140 training data: 0.03511429950594902
Epoch: 19, Training Loss on 140 training data: 0.028546130284667015
Epoch: 20, Training Loss on 140 training data: 0.0230401661247015
Epoch: 21, Training Loss on 140 training data: 0.018506357446312904
Epoch: 22, Training Loss on 140 training data: 0.014850127510726452
Epoch: 23, Training Loss on 140 training data: 0.01202170830219984
Epoch: 24, Training Loss on 140 training data: 0.009847059845924377
Epoch: 25, Training Loss on 140 training data: 0.00818885862827301
Epoch: 26, Training Loss on 140 training data: 0.006922682747244835
Epoch: 27, Training Loss on 140 training data: 0.005947056692093611
Epoch: 28, Training Loss on 140 training data: 0.00517963245511055
Epoch: 29, Training Loss on 140 training data: 0.004555115010589361
Epoch: 30, Training Loss on 140 training data: 0.00403241952881217
Epoch: 31, Training Loss on 140 training data: 0.003584714373573661
Epoch: 32, Training Loss on 140 training data: 0.003194464836269617
Epoch: 33, Training Loss on 140 training data: 0.002850515069440007
Epoch: 34, Training Loss on 140 training data: 0.002545734867453575
Epoch: 35, Training Loss on 140 training data: 0.0022753614466637373
Epoch: 36, Training Loss on 140 training data: 0.0020359582267701626
Epoch: 37, Training Loss on 140 training data: 0.0018256051698699594
Epoch: 38, Training Loss on 140 training data: 0.0016417495207861066
Epoch: 39, Training Loss on 140 training data: 0.0014815757749602199
Epoch: 40, Training Loss on 140 training data: 0.0013420513132587075
Epoch: 41, Training Loss on 140 training data: 0.001219914061948657
Epoch: 42, Training Loss on 140 training data: 0.0011134007945656776
Epoch: 43, Training Loss on 140 training data: 0.001020980766043067
Epoch: 44, Training Loss on 140 training data: 0.0009404486045241356
Epoch: 45, Training Loss on 140 training data: 0.0008707985980436206
Epoch: 46, Training Loss on 140 training data: 0.0008101455750875175
Epoch: 47, Training Loss on 140 training data: 0.0007568077417090535
Epoch: 48, Training Loss on 140 training data: 0.0007099349168129265
Epoch: 49, Training Loss on 140 training data: 0.0006686299457214773
Accuracy of the network on the 36 test data: 97.22222222222221 %, loss: 0.11734676361083984